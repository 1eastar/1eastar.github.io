---
permalink: /
title: "Dongjin Kang"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<p style="font-size:14px;">
Hi! I am a M.S. student at <a href="https://langlab.yonsei.ac.kr" target="_blank">LangAGI Lab</a> advised by <a href="https://jinyeo.weebly.com/" target="_blank">Jinyoung Yeo</a>. Previously, I received B.S. in Computer Science from Yonsei University in Feb. 2024.
<br/><br/>
My research goal is to enable digital agents to interact with their environments and master increasingly complex, long-horizon tasks. I am currently focused on: (i) Reinforcement Learning (RL)&mdash;especially exploration strategies that expand the reasoning boundaries of foundational models and the design of effective reward signals for policy learning, and (ii) Tackling the Problem of Overthinking in Models&mdash;whether by enabling them to recognize their own errors to mitigate overconfidence or by encouraging reasoning within latent spaces. Additionally, I concentrate on interpretability in language models, identifying opportunities for improvement and using those insights to enhance model performance.

<br/><br/>
</p>


## Recent News
- <p style="font-size:15px;margin-bottom:12px;">[2025.09] Our <span style="font-weight:600;">‚ÄúWeb-Sheperd‚Äù</span> on the Process Reward Model of Web Agent got accepted to <span style="font-weight:600;">NeurIPS 2025 Spotlight</span>.</p>

- <p style="font-size:15px;margin-bottom:12px;">[2025.08] Our <span style="font-weight:600;">"ToolHaystack"</span> on the Long-term Interaction of Tool-augmented Language Models is accepted to <span style="font-weight:600;">EMNLP 2025</span>.</p>

- <p style="font-size:15px;margin-bottom:12px;">[2025.05] Two papers about Long CoT and Reward Overoptimization have been accepted at <span style="font-weight:600;">ACL 2025</span>! See you in Vienna üá¶üáπ</p>

- <p style="font-size:15px;margin-bottom:12px;">[2024.08] üèÜ Our paper won the <a href="https://2024.aclweb.org/program/best_papers/" target="_blank" style="font-weight: 700">Outstanding Paper Award</a> at ACL 2024!</p>

- <p style="font-size:15px;margin-bottom:12px;">[2024.07] I am <span style="font-weight: 600">joining LG AI Research (Advanced ML Lab)</span> as an research intern. mentors: Kyungjae Lee, Moontae Lee</p>


## Publications

<p style="font-size:12px;">
<sup>‚Ä°</sup> indicates equal contribution.
</p>


### 2025

<p style="font-size:15px; margin-bottom: 0.3em;">
  <a href="https://arxiv.org/abs/2505.15277" target="_blank" style="text-decoration:none;">
  Web-Shepherd: Advancing PRMs for Reinforcing Web Agents
  </a>
</p>

<p style="font-size:12px;">
  Hyungjoo Chae<sup>‚Ä°</sup>, Sunghwan Kim<sup>‚Ä°</sup>, Junhee Cho, Seungone Kim, Seungjun Moon, Gyeom Hwangbo, Dongha Lim, Minjin Kim, Yeonjun Hwang, Minju Gwak, Dongwook Choi, Minseok Kang, Gwanhoon Im, ByeongUng Cho, Hyojun Kim, Jun Hee Han, Taeyoon Kwon, Minju Kim, Beong-woo Kwak, <u style="font-weight:bold;">Dongjin Kang</u>, Jinyoung Yeo
  <br/>
  <p style="font-size: 13px;">
  NeurIPS 2025 (Spotlight)
  </p>
</p>

___
<p style="font-size:15px; margin-bottom: 0.3em;">
  <a href="https://arxiv.org/abs/2505.23662" target="_blank" style="text-decoration:none;">
  ToolHaystack: Stress-Testing Tool-Augmented Language Models in Realistic Long-Term Interactions
  </a>
</p>

<p style="font-size:12px;">
  Beong-woo Kwak, Minju Kim, Dongha Lim, Hyungjoo Chae, <u style="font-weight:bold;">Dongjin Kang</u>, Sunghwan Kim, Dongil Yang, Jinyoung Yeo
  <br/>
  <p style="font-size: 13px;">
  EMNLP 2025 findings
  </p>
</p>
___
<p style="font-size:15px; margin-bottom: 0.3em;">
  <a href="https://arxiv.org/abs/2505.12763" target="_blank" style="text-decoration:none;">
  Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization
  </a>
</p>

<p style="font-size:12px;">
  Sunghwan Kim<sup>‚Ä°</sup>, <u style="font-weight:bold;">Dongjin Kang</u><sup>‚Ä°</sup>, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, Jinyoung Yeo
  <br/>
  <p style="font-size: 13px;">
  ACL 2025 main (Oral)
  </p>
</p>
___
<p style="font-size:15px; margin-bottom: 0.3em;">
  <a href="https://arxiv.org/abs/2506.02338" target="_blank" style="text-decoration:none;">
  One Missing Piece for Open-Source Reasoning Models: A Dataset to Mitigate Cold-Starting Short CoT LLMs in RL
  </a>
</p>

<p style="font-size:12px;">
  Hyungjoo Chae<sup>‚Ä°</sup>, <u style="font-weight:bold;">Dongjin Kang</u><sup>‚Ä°</sup>, Jihyuk Kim, Beong-woo Kwak, Sunghyun Park, Haeju Park, Jinyoung Yeo, Moontae Lee, Kyungjae Lee
  <br/>
  <p style="font-size: 13px;">
  ACL 2024 Industry
  </p>
</p>

___


### 2024
<p style="font-size:15px; margin-bottom: 0.3em;">
  <a href="https://arxiv.org/abs/2410.01729" target="_blank" style="text-decoration:none;">
  Evaluating Robustness of Reward Models for Mathematical Reasoning
  </a>
</p>

<p style="font-size:12px;">
  Sunghwan Kim<sup>‚Ä°</sup>, <u style="font-weight:bold;">Dongjin Kang</u><sup>‚Ä°</sup>, Taeyoon Kwon, Hyungjoo Chae, Jungsoo Won, Dongha Lee, Jinyoung Yeo
  <br/>

  <p style="font-size: 13px;">
  Arxiv preprint.
  </p>
</p>
___
<p style="font-size:15px; margin-bottom: 0.3em;">
  <a href="https://arxiv.org/abs/2409.19715" target="_blank" style="text-decoration:none;">
  Coffee-gym: An environment for evaluating and improving natural language feedback on erroneous code
  </a>
</p>

<p style="font-size:12px;">
  Hyungjoo Chae<sup>‚Ä°</sup>, Taeyoon Kwon<sup>‚Ä°</sup>, Seungjun Moon<sup>‚Ä°</sup>, Yongho Song, <u style="font-weight:bold;">Dongjin Kang</u>, Kai Tzu-iunn Ong, Beong-woo Kwak, Seonghyeon Bae, Seung-won Hwang, Jinyoung Yeo
  <br/>
  <p style="font-size: 13px;">
  EMNLP 2024 main
  </p>
</p>

___
<p style="font-size:15px; margin-bottom: 0.3em;">
  <a href="https://arxiv.org/abs/2407.03103" target="_blank" style="text-decoration:none;">
  Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory
  </a>
</p>

<p style="font-size:12px;">
  Suyeon Lee<sup>‚Ä°</sup>, Sunghwan Kim<sup>‚Ä°</sup>, Minju Kim<sup>‚Ä°</sup>, <u style="font-weight:bold;">Dongjin Kang</u>, Dongil Yang, Harim Kim, Minseok Kang, Dayi Jung, Min Hee Kim, Seungbeen Lee, Kyoung-Mee Chung, Youngjae Yu, Dongha Lee, Jinyoung Yeo
  <br/>
  <p style="font-size: 13px;">
  EMNLP 2024 findings
  </p>
</p>

___
<p style="font-size:15px; margin-bottom: 0.3em;">
  <span style="font-size:18px;">üèÜ</span>
  <a href="https://arxiv.org/abs/2402.13211" target="_blank" style="text-decoration:none;">
  Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation
  </a>
</p>

<p style="font-size:12px;">
  <u style="font-weight:bold;">Dongjin Kang</u><sup>‚Ä°</sup>, Sunghwan Kim<sup>‚Ä°</sup>, Taeyoon Kwon, Seungjun Moon, Hyunsouk Cho, Youngjae Yu, Dongha Lee, Jinyoung Yeo
  <br/>
  <p style="font-size: 13px;">
  <span style="font-weight:900; color: #ea3800">[Outstanding Paper Award]</span> ACL 2024 main
  </p>
</p>

___
<p style="font-size:15px; margin-bottom: 0.3em;">
  <a href="https://arxiv.org/abs/2311.07215" target="_blank" style="text-decoration:none;">
  Coffee: Boost your code llms by fixing bugs with feedback
  </a>
</p>

<p style="font-size:12px;">
  Seungjun Moon<sup>‚Ä°</sup>, Yongho Song<sup>‚Ä°</sup>, Hyungjoo Chae<sup>‚Ä°</sup>, Taeyoon Kwon, <u style="font-weight:bold;">Dongjin Kang</u>, Kai Tzu-iunn Ong, Seung-won Hwang, Jinyoung Yeo
  <br/>
  <p style="font-size: 13px;">
  Arxiv Preprint
  </p>
</p>

___
<p style="font-size:15px; margin-bottom: 0.3em;">
  <a href="https://arxiv.org/abs/2312.07399" target="_blank" style="text-decoration:none;">
  Large language models are clinical reasoners: Reasoning-aware diagnosis framework with prompt-generated rationales
  </a>
</p>

<p style="font-size:12px;">
  Taeyoon Kwon<sup>‚Ä°</sup>, Kai Tzu-iunn Ong<sup>‚Ä°</sup>, <u style="font-weight:bold;">Dongjin Kang</u>, Seungjun Moon, Jeong Ryong Lee, Dosik Hwang, Yongsik Sim, Beomseok Sohn, Dongha Lee, Jinyoung Yeo
  <br/>
  <p style="font-size: 13px;">
  AAAI 2024
  </p>
</p>



## Industrial Experience

<p style="font-size:13px; margin-bottom: 1em;">
  <strong style="font-size:15px;">LG AI Research</strong> <span style="float:right;font-weight:300;font-size:14px;">Aug 2024 ‚Äì Apr 2025</span><br/>
  Research Intern<br/>
  > One Missing Piece for Open-Source Reasoning Models: A Dataset to Mitigate Cold-Starting Short CoT LLMs in RL<br/>
  <em>Mentors: Moontae Lee, Kyungjae Lee</em>
</p>

<p style="font-size:13px; margin-bottom: 1em;">
  <strong style="font-size:15px;">Lingora, Market Designers Inc.</strong> <span style="float:right;font-weight:300;font-size:14px;">Apr 2024 ‚Äì Jul 2024</span><br/>
  Build/Optimize an AI English tutor for learners<br/>
  <em>Advisor: Prof. Jinyoung Yeo</em>
</p>

<p style="font-size:13px; margin-bottom: 1em;">
  <strong style="font-size:15px;">Bagstrap, Outstanders Inc.</strong> <span style="float:right;font-weight:300;font-size:14px;">Oct 2022 ‚Äì Jun 2023</span><br/>
  Front-end Engineer
</p>

<p style="font-size:13px; margin-bottom: 1em;">
  <strong style="font-size:15px;">Channel Talk</strong> <span style="float:right;font-weight:300;font-size:14px;">Aug 2020 ‚Äì Jan 2021</span><br/>
  Software Engineer (Web Front-end)
</p>

<br/>

## Education

<p style="font-size:13px; margin-bottom: 1em;">
  <strong style="font-size:15px;">Yonsei University</strong>, Seoul, South Korea <span style="float:right;font-weight:300;font-size:14px;">2024 ‚Äì 2025</span><br/>
  M.S. in Computer Science (Advisor: Prof. Jinyoung Yeo)<br/>
  <!-- <em>Thesis: Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation</em> -->
</p>

<p style="font-size:13px; margin-bottom: 1em;">
  <strong style="font-size:15px;">Yonsei University</strong>, Seoul, South Korea <span style="float:right;font-weight:300;font-size:14px;">2017 ‚Äì 2023</span><br/>
  B.S. in Computer Science<br/>
  <!-- <em>Graduation Project: Emotional Support Conversation on Large Language Models</em> -->
</p>
